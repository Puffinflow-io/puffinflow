export const resourceManagementMarkdown = `# Resource Management

Control CPU, memory, GPU, and custom resources to build scalable, production-ready workflows. Puffinflow provides intelligent resource allocation, quota management, and optimization patterns to prevent resource exhaustion and ensure fair allocation.

---

## Quick Start: Resource-Controlled Workflow

**See resource management in action with a complete example:**

**File: resource_demo.py**

\`\`\`python
     1â†’import asyncio
     2â†’from puffinflow import Agent, state, Priority, cpu_intensive, memory_intensive
     3â†’from puffinflow.core.resources import ResourcePool, PriorityAllocator
     4â†’
     5â†’# Create resource pool with limits
     6â†’resource_pool = ResourcePool(
     7â†’    total_cpu=8.0,      # 8 CPU cores available
     8â†’    total_memory=16384,  # 16GB memory available
     9â†’    total_gpu=2.0,      # 2 GPU units available
    10â†’    allocator=PriorityAllocator()
    11â†’)
    12â†’
    13â†’# Create agent with resource management
    14â†’agent = Agent("resource-demo", resource_pool=resource_pool)
    15â†’
    16â†’@state(cpu=1.0, memory=256, timeout=30.0, priority=Priority.NORMAL)
    17â†’async def fetch_data(context):
    18â†’    print("ðŸ“Š Fetching data (light resource usage)...")
    19â†’    await asyncio.sleep(1)
    20â†’    context.set_variable("raw_data", list(range(10000)))
    21â†’    print("âœ… Data fetched")
    22â†’    return "process_data"
    23â†’
    24â†’@cpu_intensive  # Uses 4.0 CPU, 1024MB memory profile
    25â†’async def process_data(context):
    26â†’    print("ðŸ”¥ CPU-intensive processing...")
    27â†’    data = context.get_variable("raw_data")
    28â†’    
    29â†’    # Simulate CPU-heavy work
    30â†’    result = sum(x * x for x in data)
    31â†’    await asyncio.sleep(2)
    32â†’    
    33â†’    context.set_variable("processed_result", result)
    34â†’    print(f"âœ… Processing complete: {result}")
    35â†’    return "analyze_memory"
    36â†’
    37â†’@memory_intensive  # Uses 2.0 CPU, 4096MB memory profile
    38â†’async def analyze_memory(context):
    39â†’    print("ðŸ’¾ Memory-intensive analysis...")
    40â†’    
    41â†’    # Simulate memory-heavy work
    42â†’    large_data = [[i] * 1000 for i in range(1000)]
    43â†’    analysis = {"memory_usage": "high", "data_size": len(large_data)}
    44â†’    
    45â†’    context.set_variable("analysis", analysis)
    46â†’    print("âœ… Memory analysis complete")
    47â†’    return "gpu_task"
    48â†’
    49â†’@state(cpu=2.0, memory=2048, gpu=1.0, timeout=60.0, priority=Priority.HIGH)
    50â†’async def gpu_task(context):
    51â†’    print("ðŸŽ® GPU-accelerated computation...")
    52â†’    await asyncio.sleep(1.5)
    53â†’    
    54â†’    gpu_result = {"model_inference": "complete", "accuracy": 0.95}
    55â†’    context.set_variable("gpu_result", gpu_result)
    56â†’    print("âœ… GPU task complete")
    57â†’    return None
    58â†’
    59â†’# Register states
    60â†’agent.add_state("fetch_data", fetch_data)
    61â†’agent.add_state("process_data", process_data, dependencies=["fetch_data"])
    62â†’agent.add_state("analyze_memory", analyze_memory, dependencies=["process_data"])
    63â†’agent.add_state("gpu_task", gpu_task, dependencies=["analyze_memory"])
    64â†’
    65â†’async def main():
    66â†’    print("ðŸš€ Starting resource-managed workflow...")
    67â†’    print(f"Available resources: {resource_pool.total_cpu} CPU, {resource_pool.total_memory}MB RAM, {resource_pool.total_gpu} GPU")
    68â†’    
    69â†’    result = await agent.run()
    70â†’    
    71â†’    print("ðŸŽ¯ Workflow complete!")
    72â†’    print(f"Final results: {result.get_variable('gpu_result')}")
    73â†’
    74â†’if __name__ == "__main__":
    75â†’    asyncio.run(main())
\`\`\`

**Run the example:**
\`\`\`bash
python resource_demo.py
\`\`\`

**Output:**
\`\`\`
ðŸš€ Starting resource-managed workflow...
Available resources: 8.0 CPU, 16384MB RAM, 2.0 GPU
ðŸ“Š Fetching data (light resource usage)...
âœ… Data fetched
ðŸ”¥ CPU-intensive processing...
âœ… Processing complete: 333283335000
ðŸ’¾ Memory-intensive analysis...
âœ… Memory analysis complete
ðŸŽ® GPU-accelerated computation...
âœ… GPU task complete  
ðŸŽ¯ Workflow complete!
Final results: {'model_inference': 'complete', 'accuracy': 0.95}
\`\`\`

---

## Resource Types and Allocation

### System Resources

Puffinflow manages these core system resources:

| Resource | Unit | Range | Purpose | Example Usage |
|----------|------|-------|---------|---------------|
| **CPU** | Cores | 0.1 - 16.0 | Processing power | Machine learning, data processing |
| **Memory** | MB | 64 - 32768 | RAM allocation | Large datasets, caching |
| **GPU** | Units | 0.0 - 8.0 | Graphics processing | Neural networks, image processing |
| **I/O** | Weight | 0.1 - 10.0 | Disk/network priority | File operations, database queries |
| **Network** | Weight | 0.1 - 10.0 | Network bandwidth | API calls, data transfer |

### Resource Profiles

**Ready-to-use profiles for common scenarios:**

**File: profiles_demo.py**

\`\`\`python
     1â†’from puffinflow import state, cpu_intensive, memory_intensive, gpu_accelerated
     2â†’from puffinflow import io_intensive, network_intensive, critical_state
     3â†’
     4â†’# Predefined profiles with automatic resource allocation
     5â†’
     6â†’@state(profile='minimal')      # 0.1 CPU, 50MB memory, 30s timeout
     7â†’async def lightweight_task(context):
     8â†’    print("âš¡ Minimal resource task")
     9â†’
    10â†’@state(profile='standard')     # 1.0 CPU, 100MB memory, 60s timeout
    11â†’async def balanced_task(context):
    12â†’    print("âš–ï¸ Standard balanced task")
    13â†’
    14â†’@cpu_intensive                 # 4.0 CPU, 1024MB memory, 300s timeout
    15â†’async def machine_learning_training(context):
    16â†’    print("ðŸ§  Training ML model...")
    17â†’
    18â†’@memory_intensive              # 2.0 CPU, 4096MB memory, 600s timeout
    19â†’async def big_data_processing(context):
    20â†’    print("ðŸ“Š Processing large dataset...")
    21â†’
    22â†’@gpu_accelerated               # 2.0 CPU, 2048MB memory, 1.0 GPU, 900s timeout
    23â†’async def neural_network_inference(context):
    24â†’    print("ðŸŽ¯ Running neural network inference...")
    25â†’
    26â†’@io_intensive                  # 1.0 CPU, 256MB memory, circuit breaker enabled
    27â†’async def file_processing(context):
    28â†’    print("ðŸ“ Processing files...")
    29â†’
    30â†’@network_intensive             # 1.0 CPU, 512MB memory, retry policies
    31â†’async def api_integration(context):
    32â†’    print("ðŸŒ Calling external APIs...")
    33â†’
    34â†’@critical_state                # 4.0 CPU, 2048MB memory, highest priority
    35â†’async def emergency_response(context):
    36â†’    print("ðŸš¨ Critical operation...")
\`\`\`

---

## Advanced Resource Control

### Custom Resource Requirements

Define precise resource needs with ResourceRequirements:

**File: custom_resources.py**

\`\`\`python
     1â†’from puffinflow.core.resources import ResourceRequirements, ResourceType
     2â†’from puffinflow import Agent, state
     3â†’
     4â†’# Define custom resource requirements
     5â†’requirements = ResourceRequirements(
     6â†’    cpu_units=3.5,              # 3.5 CPU cores
     7â†’    memory_mb=2048.0,           # 2GB memory
     8â†’    io_weight=2.0,              # High I/O priority
     9â†’    network_weight=1.5,         # Medium network priority
    10â†’    gpu_units=0.5,              # Half GPU unit
    11â†’    priority_boost=10,          # Priority adjustment
    12â†’    timeout=180.0,              # 3 minute timeout
    13â†’    resource_types=ResourceType.CPU | ResourceType.MEMORY | ResourceType.GPU
    14â†’)
    15â†’
    16â†’@state(
    17â†’    cpu=requirements.cpu_units,
    18â†’    memory=int(requirements.memory_mb),
    19â†’    gpu=requirements.gpu_units,
    20â†’    timeout=requirements.timeout,
    21â†’    io_weight=requirements.io_weight
    22â†’)
    23â†’async def custom_resource_task(context):
    24â†’    print(f"ðŸ”§ Running with custom resources:")
    25â†’    print(f"   CPU: {requirements.cpu_units} cores")
    26â†’    print(f"   Memory: {requirements.memory_mb}MB")
    27â†’    print(f"   GPU: {requirements.gpu_units} units")
    28â†’    print(f"   I/O Weight: {requirements.io_weight}")
    29â†’    
    30â†’    # Simulate resource-intensive work
    31â†’    await asyncio.sleep(2)
    32â†’    print("âœ… Custom resource task complete")
\`\`\`

### Resource Pools and Allocation Strategies

**Control how resources are allocated across states:**

**File: resource_pools.py**

\`\`\`python
     1â†’from puffinflow.core.resources import (
     2â†’    ResourcePool, FirstFitAllocator, BestFitAllocator,
     3â†’    PriorityAllocator, FairShareAllocator
     4â†’)
     5â†’from puffinflow import Agent, state, Priority
     6â†’
     7â†’# Strategy 1: First Fit (fastest allocation)
     8â†’first_fit_pool = ResourcePool(
     9â†’    total_cpu=16.0,
    10â†’    total_memory=32768,
    11â†’    allocator=FirstFitAllocator()  # First available slot
    12â†’)
    13â†’
    14â†’# Strategy 2: Best Fit (most efficient)
    15â†’best_fit_pool = ResourcePool(
    16â†’    total_cpu=16.0,
    17â†’    total_memory=32768,
    18â†’    allocator=BestFitAllocator()  # Most efficient fit
    19â†’)
    20â†’
    21â†’# Strategy 3: Priority-based (high priority first)
    22â†’priority_pool = ResourcePool(
    23â†’    total_cpu=16.0,
    24â†’    total_memory=32768,
    25â†’    allocator=PriorityAllocator()  # Priority-based allocation
    26â†’)
    27â†’
    28â†’# Strategy 4: Fair Share (equal distribution)
    29â†’fair_share_pool = ResourcePool(
    30â†’    total_cpu=16.0,
    31â†’    total_memory=32768,
    32â†’    allocator=FairShareAllocator()  # Equal distribution
    33â†’)
    34â†’
    35â†’# Create agents with different allocation strategies
    36â†’fast_agent = Agent("fast-allocator", resource_pool=first_fit_pool)
    37â†’efficient_agent = Agent("efficient-allocator", resource_pool=best_fit_pool)
    38â†’priority_agent = Agent("priority-allocator", resource_pool=priority_pool)
    39â†’fair_agent = Agent("fair-allocator", resource_pool=fair_share_pool)
    40â†’
    41â†’@state(cpu=2.0, memory=1024, priority=Priority.HIGH)
    42â†’async def high_priority_task(context):
    43â†’    print("ðŸ”¥ High priority task executing...")
    44â†’    await asyncio.sleep(1)
    45â†’    print("âœ… High priority task complete")
    46â†’
    47â†’@state(cpu=1.0, memory=512, priority=Priority.LOW)
    48â†’async def low_priority_task(context):
    49â†’    print("ðŸ“‹ Low priority task executing...")
    50â†’    await asyncio.sleep(2)
    51â†’    print("âœ… Low priority task complete")
\`\`\`

---

## Resource Monitoring and Optimization

### Real-time Resource Tracking

**Monitor resource usage during workflow execution:**

**File: resource_monitoring.py**

\`\`\`python
     1â†’import asyncio
     2â†’import time
     3â†’from puffinflow import Agent, state
     4â†’from puffinflow.core.resources import ResourcePool, ResourceMonitor
     5â†’
     6â†’# Create monitored resource pool
     7â†’pool = ResourcePool(total_cpu=8.0, total_memory=8192)
     8â†’monitor = ResourceMonitor(pool)
     9â†’agent = Agent("monitored-agent", resource_pool=pool)
    10â†’
    11â†’@state(cpu=2.0, memory=1024, timeout=60.0)
    12â†’async def resource_tracked_task(context):
    13â†’    print("ðŸ“Š Starting resource-tracked task...")
    14â†’    
    15â†’    # Get current resource usage
    16â†’    usage_start = monitor.get_current_usage()
    17â†’    print(f"ðŸ”‹ Resources at start: {usage_start.cpu_used}/{usage_start.cpu_total} CPU, {usage_start.memory_used}/{usage_start.memory_total}MB memory")
    18â†’    
    19â†’    # Simulate work with periodic monitoring
    20â†’    for i in range(5):
    21â†’        await asyncio.sleep(0.5)
    22â†’        current_usage = monitor.get_current_usage()
    23â†’        print(f"   Step {i+1}: CPU {current_usage.cpu_utilization:.1f}%, Memory {current_usage.memory_utilization:.1f}%")
    24â†’    
    25â†’    # Check for resource warnings
    26â†’    if monitor.is_resource_constrained():
    27â†’        print("âš ï¸ System under resource pressure")
    28â†’        
    29â†’        # Get resource recommendations
    30â†’        recommendations = monitor.get_optimization_recommendations()
    31â†’        for rec in recommendations:
    32â†’            print(f"ðŸ’¡ Recommendation: {rec}")
    33â†’    
    34â†’    usage_end = monitor.get_current_usage()
    35â†’    print(f"ðŸ Resources at end: {usage_end.cpu_used}/{usage_end.cpu_total} CPU, {usage_end.memory_used}/{usage_end.memory_total}MB memory")
    36â†’    
    37â†’    # Store resource metrics
    38â†’    context.set_output("resource_metrics", {
    39â†’        "start_cpu_utilization": usage_start.cpu_utilization,
    40â†’        "end_cpu_utilization": usage_end.cpu_utilization,
    41â†’        "start_memory_utilization": usage_start.memory_utilization,
    42â†’        "end_memory_utilization": usage_end.memory_utilization,
    43â†’        "peak_cpu": monitor.get_peak_cpu_usage(),
    44â†’        "peak_memory": monitor.get_peak_memory_usage()
    45â†’    })
    46â†’    
    47â†’    print("âœ… Resource tracking complete")
    48â†’
    49â†’# Add resource monitoring callbacks
    50â†’@monitor.on_resource_threshold(cpu_threshold=0.8, memory_threshold=0.9)
    51â†’async def resource_warning_callback(usage_info):
    52â†’    print(f"ðŸš¨ Resource Warning: CPU {usage_info.cpu_utilization:.1f}%, Memory {usage_info.memory_utilization:.1f}%")
    53â†’
    54â†’@monitor.on_resource_exhausted()
    55â†’async def resource_exhausted_callback(resource_type):
    56â†’    print(f"ðŸ’¥ Resource Exhausted: {resource_type}")
    57â†’    # Could implement emergency response here
\`\`\`

### Resource Leak Detection

**Automatically detect and handle resource leaks:**

**File: leak_detection.py**

\`\`\`python
     1â†’from puffinflow import Agent, state
     2â†’from puffinflow.core.resources import ResourceLeakDetector, LeakDetectionConfig
     3â†’
     4â†’# Configure leak detection
     5â†’leak_config = LeakDetectionConfig(
     6â†’    memory_threshold_mb=1000,     # Alert if memory usage exceeds 1GB
     7â†’    cpu_threshold_percent=80,     # Alert if CPU usage exceeds 80%
     8â†’    monitoring_interval=5.0,      # Check every 5 seconds
     9â†’    leak_tolerance_duration=30.0, # Allow high usage for 30s before alerting
    10â†’    auto_cleanup=True             # Automatically clean up detected leaks
    11â†’)
    12â†’
    13â†’leak_detector = ResourceLeakDetector(leak_config)
    14â†’agent = Agent("leak-monitored-agent")
    15â†’
    16â†’@state(cpu=1.0, memory=512, timeout=120.0)
    17â†’async def potential_leak_task(context):
    18â†’    print("ðŸ” Task with potential resource leak...")
    19â†’    
    20â†’    # Start leak detection for this task
    21â†’    with leak_detector.monitor_task("potential_leak_task"):
    22â†’        # Simulate gradual memory leak
    23â†’        data_accumulator = []
    24â†’        
    25â†’        for i in range(100):
    26â†’            # Each iteration "leaks" more memory
    27â†’            large_data = [j for j in range(i * 1000)]
    28â†’            data_accumulator.append(large_data)
    29â†’            
    30â†’            await asyncio.sleep(0.1)
    31â†’            
    32â†’            # Check if leak detector found issues
    33â†’            if leak_detector.has_detected_leaks():
    34â†’                print("ðŸš¨ Memory leak detected!")
    35â†’                leaks = leak_detector.get_detected_leaks()
    36â†’                
    37â†’                for leak in leaks:
    38â†’                    print(f"   Leak type: {leak.resource_type}")
    39â†’                    print(f"   Current usage: {leak.current_usage}")
    40â†’                    print(f"   Threshold: {leak.threshold}")
    41â†’                    print(f"   Duration: {leak.duration_seconds}s")
    42â†’                
    43â†’                # Manual cleanup if auto_cleanup is disabled
    44â†’                if not leak_config.auto_cleanup:
    45â†’                    print("ðŸ§¹ Manual cleanup triggered")
    46â†’                    data_accumulator.clear()  # Clean up the leak
    47â†’                    break
    48â†’    
    49â†’    print("âœ… Task complete (leak detection finished)")
    50â†’
    51â†’# Leak detection callbacks
    52â†’@leak_detector.on_leak_detected
    53â†’async def handle_memory_leak(leak_info):
    54â†’    print(f"ðŸ’§ Leak detected in {leak_info.task_name}: {leak_info.resource_type}")
    55â†’    
    56â†’    # Could implement custom cleanup logic here
    57â†’    if leak_info.severity == "critical":
    58â†’        print("ðŸš¨ Critical leak - implementing emergency measures")
    59â†’        # Emergency response (restart task, scale resources, etc.)
    60â†’
    61â†’@leak_detector.on_leak_resolved
    62â†’async def handle_leak_resolved(leak_info):
    63â†’    print(f"âœ… Leak resolved in {leak_info.task_name}")
\`\`\`

---

## Resource Quotas and Limits

### Setting Resource Quotas

**Enforce resource limits and quotas across workflows:**

**File: resource_quotas.py**

\`\`\`python
     1â†’from puffinflow import Agent, state, Priority
     2â†’from puffinflow.core.resources import ResourceQuota, QuotaManager, QuotaPolicy
     3â†’
     4â†’# Define resource quotas for different user types
     5â†’basic_quota = ResourceQuota(
     6â†’    max_cpu=2.0,           # 2 CPU cores max
     7â†’    max_memory=1024,       # 1GB memory max
     8â†’    max_gpu=0.0,           # No GPU access
     9â†’    max_concurrent_states=3,  # 3 states max at once
    10â†’    daily_cpu_hours=10.0,  # 10 CPU hours per day
    11â†’    daily_memory_gb_hours=5.0  # 5GB-hours per day
    12â†’)
    13â†’
    14â†’premium_quota = ResourceQuota(
    15â†’    max_cpu=8.0,           # 8 CPU cores max
    16â†’    max_memory=8192,       # 8GB memory max
    17â†’    max_gpu=2.0,           # 2 GPU units max
    18â†’    max_concurrent_states=10,  # 10 states max at once
    19â†’    daily_cpu_hours=100.0, # 100 CPU hours per day
    20â†’    daily_memory_gb_hours=50.0  # 50GB-hours per day
    21â†’)
    22â†’
    23â†’# Create quota manager
    24â†’quota_manager = QuotaManager()
    25â†’quota_manager.set_user_quota("basic_user", basic_quota)
    26â†’quota_manager.set_user_quota("premium_user", premium_quota)
    27â†’
    28â†’# Quota policy configuration
    29â†’quota_policy = QuotaPolicy(
    30â†’    enforcement_mode="strict",     # strict, warning, or disabled
    31â†’    grace_period_seconds=60.0,     # Allow 60s over quota
    32â†’    quota_reset_schedule="daily",  # daily, weekly, monthly
    33â†’    overage_penalty_factor=2.0     # 2x resource cost for overages
    34â†’)
    35â†’
    36â†’quota_manager.set_policy(quota_policy)
    37â†’
    38â†’# Create agent with quota enforcement
    39â†’agent = Agent("quota-managed-agent")
    40â†’agent.set_quota_manager(quota_manager)
    41â†’
    42â†’@state(cpu=1.0, memory=512, timeout=60.0)
    43â†’async def quota_checked_task(context):
    44â†’    print("ðŸŽ« Starting quota-checked task...")
    45â†’    
    46â†’    # Get current quota usage
    47â†’    user_id = context.get_variable("user_id", "basic_user")
    48â†’    quota_usage = quota_manager.get_user_usage(user_id)
    49â†’    
    50â†’    print(f"ðŸ“Š Current quota usage for {user_id}:")
    51â†’    print(f"   CPU: {quota_usage.cpu_used:.1f}/{quota_usage.cpu_limit:.1f} cores")
    52â†’    print(f"   Memory: {quota_usage.memory_used}/{quota_usage.memory_limit}MB")
    53â†’    print(f"   GPU: {quota_usage.gpu_used:.1f}/{quota_usage.gpu_limit:.1f} units")
    54â†’    print(f"   Daily CPU hours: {quota_usage.daily_cpu_hours_used:.1f}/{quota_usage.daily_cpu_hours_limit:.1f}")
    55â†’    
    56â†’    # Check if we're approaching limits
    57â†’    if quota_usage.is_approaching_limit(threshold=0.8):
    58â†’        print("âš ï¸ Approaching quota limits")
    59â†’        approaching_limits = quota_usage.get_approaching_limits()
    60â†’        for limit_type in approaching_limits:
    61â†’            print(f"   {limit_type} usage is at {quota_usage.get_utilization(limit_type):.1f}%")
    62â†’    
    63â†’    # Simulate work
    64â†’    await asyncio.sleep(2)
    65â†’    
    66â†’    print("âœ… Quota-checked task complete")
    67â†’
    68â†’# Quota violation handlers
    69â†’@quota_manager.on_quota_exceeded
    70â†’async def handle_quota_exceeded(user_id, resource_type, current_usage, limit):
    71â†’    print(f"ðŸš« Quota exceeded for {user_id}: {resource_type} usage {current_usage} > limit {limit}")
    72â†’    
    73â†’    # Could implement quota upgrade prompts, throttling, etc.
    74â†’    if resource_type == "cpu":
    75â†’        print("ðŸ’¡ Consider upgrading to premium for higher CPU limits")
    76â†’
    77â†’@quota_manager.on_quota_warning
    78â†’async def handle_quota_warning(user_id, resource_type, utilization_percent):
    79â†’    print(f"âš ï¸ Quota warning for {user_id}: {resource_type} at {utilization_percent:.1f}% capacity")
\`\`\`

---

## Performance Optimization Patterns

### Resource-Aware Task Scheduling

**Optimize task execution based on available resources:**

**File: resource_scheduling.py**

\`\`\`python
     1â†’from puffinflow import Agent, state, Priority
     2â†’from puffinflow.core.resources import ResourceAwareScheduler, SchedulingStrategy
     3â†’
     4â†’# Create resource-aware scheduler
     5â†’scheduler = ResourceAwareScheduler(
     6â†’    strategy=SchedulingStrategy.RESOURCE_OPTIMAL,  # Balance resource utilization
     7â†’    preemption_enabled=True,                       # Allow high priority preemption
     8â†’    load_balancing_enabled=True,                   # Distribute load evenly
     9â†’    resource_prediction_enabled=True              # Predict resource needs
    10â†’)
    11â†’
    12â†’agent = Agent("resource-scheduled-agent")
    13â†’agent.set_scheduler(scheduler)
    14â†’
    15â†’# States with different resource profiles
    16â†’@state(cpu=0.5, memory=128, priority=Priority.LOW)
    17â†’async def background_cleanup(context):
    18â†’    print("ðŸ§¹ Background cleanup (low priority, light resources)...")
    19â†’    await asyncio.sleep(5)  # Long-running but low priority
    20â†’    print("âœ… Cleanup complete")
    21â†’
    22â†’@state(cpu=2.0, memory=1024, priority=Priority.NORMAL)
    23â†’async def data_processing(context):
    24â†’    print("âš™ï¸ Data processing (normal priority, moderate resources)...")
    25â†’    await asyncio.sleep(3)
    26â†’    context.set_variable("processed_data", {"status": "complete"})
    27â†’    print("âœ… Data processing complete")
    28â†’    return "generate_report"
    29â†’
    30â†’@state(cpu=1.0, memory=512, priority=Priority.HIGH)
    31â†’async def generate_report(context):
    32â†’    print("ðŸ“Š Report generation (high priority)...")
    33â†’    processed_data = context.get_variable("processed_data")
    34â†’    await asyncio.sleep(1)
    35â†’    print("âœ… Report generated")
    36â†’
    37â†’@state(cpu=4.0, memory=2048, priority=Priority.CRITICAL)
    38â†’async def emergency_analysis(context):
    39â†’    print("ðŸš¨ Emergency analysis (critical priority, high resources)...")
    40â†’    await asyncio.sleep(2)
    41â†’    print("âœ… Emergency analysis complete")
    42â†’
    43â†’# Register states
    44â†’agent.add_state("cleanup", background_cleanup)
    45â†’agent.add_state("process", data_processing)
    46â†’agent.add_state("report", generate_report)
    47â†’agent.add_state("emergency", emergency_analysis)
    48â†’
    49â†’async def demonstrate_scheduling():
    50â†’    print("ðŸŽ¯ Demonstrating resource-aware scheduling...")
    51â†’    
    52â†’    # Start multiple workflows with different priorities
    53â†’    tasks = []
    54â†’    
    55â†’    # Start background cleanup (low priority)
    56â†’    cleanup_agent = Agent("cleanup-agent")
    57â†’    cleanup_agent.add_state("cleanup", background_cleanup)
    58â†’    tasks.append(cleanup_agent.run())
    59â†’    
    60â†’    # Start normal data processing
    61â†’    process_agent = Agent("process-agent")
    62â†’    process_agent.add_state("process", data_processing)
    63â†’    process_agent.add_state("report", generate_report)
    64â†’    tasks.append(process_agent.run())
    65â†’    
    66â†’    # Emergency task (should preempt others)
    67â†’    emergency_agent = Agent("emergency-agent")
    68â†’    emergency_agent.add_state("emergency", emergency_analysis)
    69â†’    tasks.append(emergency_agent.run())
    70â†’    
    71â†’    # Wait for all tasks
    72â†’    results = await asyncio.gather(*tasks)
    73â†’    print("ðŸ All scheduled tasks complete")
    74â†’    
    75â†’    return results
\`\`\`

### Resource Pooling Strategies

**Implement different pooling strategies for optimal resource usage:**

**File: pooling_strategies.py**

\`\`\`python
     1â†’from puffinflow import Agent, state
     2â†’from puffinflow.core.resources import (
     3â†’    DynamicResourcePool, StaticResourcePool,
     4â†’    ElasticResourcePool, HierarchicalResourcePool
     5â†’)
     6â†’
     7â†’# Strategy 1: Static Pool (fixed resources)
     8â†’static_pool = StaticResourcePool(
     9â†’    total_cpu=8.0,
    10â†’    total_memory=16384,
    11â†’    total_gpu=2.0
    12â†’)
    13â†’
    14â†’# Strategy 2: Dynamic Pool (adjusts based on demand)
    15â†’dynamic_pool = DynamicResourcePool(
    16â†’    min_cpu=2.0,           # Minimum guaranteed resources
    17â†’    max_cpu=16.0,          # Maximum available resources
    18â†’    min_memory=1024,
    19â†’    max_memory=32768,
    20â†’    scaling_factor=1.5,    # Scale by 1.5x when needed
    21â†’    scale_up_threshold=0.8, # Scale up at 80% utilization
    22â†’    scale_down_threshold=0.3 # Scale down at 30% utilization
    23â†’)
    24â†’
    25â†’# Strategy 3: Elastic Pool (cloud-like scaling)
    26â†’elastic_pool = ElasticResourcePool(
    27â†’    base_cpu=4.0,          # Always-available base resources
    28â†’    base_memory=4096,
    29â†’    burst_cpu=12.0,        # Additional burst capacity
    30â†’    burst_memory=12288,
    31â†’    burst_cost_multiplier=2.0,  # Burst resources cost 2x
    32â†’    burst_timeout=300.0    # Burst capacity timeout
    33â†’)
    34â†’
    35â†’# Strategy 4: Hierarchical Pool (tiered resource allocation)
    36â†’hierarchical_pool = HierarchicalResourcePool([
    37â†’    {"name": "critical", "cpu": 4.0, "memory": 8192, "priority": "CRITICAL"},
    38â†’    {"name": "high", "cpu": 2.0, "memory": 4096, "priority": "HIGH"},
    39â†’    {"name": "normal", "cpu": 1.0, "memory": 2048, "priority": "NORMAL"},
    40â†’    {"name": "low", "cpu": 0.5, "memory": 1024, "priority": "LOW"}
    41â†’])
    42â†’
    43â†’# Demonstrate different pooling strategies
    44â†’agents = {
    45â†’    "static": Agent("static-agent", resource_pool=static_pool),
    46â†’    "dynamic": Agent("dynamic-agent", resource_pool=dynamic_pool),
    47â†’    "elastic": Agent("elastic-agent", resource_pool=elastic_pool),
    48â†’    "hierarchical": Agent("hierarchical-agent", resource_pool=hierarchical_pool)
    49â†’}
    50â†’
    51â†’@state(cpu=2.0, memory=1024, timeout=30.0)
    52â†’async def test_pooling_strategy(context):
    53â†’    strategy_name = context.get_variable("strategy_name")
    54â†’    print(f"ðŸŽ¯ Testing {strategy_name} pooling strategy...")
    55â†’    
    56â†’    # Simulate resource-intensive work
    57â†’    await asyncio.sleep(2)
    58â†’    
    59â†’    print(f"âœ… {strategy_name} strategy test complete")
    60â†’    return {"strategy": strategy_name, "status": "success"}
    61â†’
    62â†’async def compare_pooling_strategies():
    63â†’    print("ðŸ”¬ Comparing resource pooling strategies...")
    64â†’    
    65â†’    results = {}
    66â†’    
    67â†’    for strategy_name, agent in agents.items():
    68â†’        agent.add_state("test", test_pooling_strategy)
    69â†’        
    70â†’        start_time = time.time()
    71â†’        result = await agent.run(initial_context={"strategy_name": strategy_name})
    72â†’        end_time = time.time()
    73â†’        
    74â†’        results[strategy_name] = {
    75â†’            "execution_time": end_time - start_time,
    76â†’            "result": result.get_variable("strategy_name")
    77â†’        }
    78â†’    
    79â†’    print("ðŸ“Š Pooling Strategy Comparison Results:")
    80â†’    for strategy, data in results.items():
    81â†’        print(f"   {strategy}: {data['execution_time']:.2f}s")
    82â†’    
    83â†’    return results
\`\`\`

---

## Production Best Practices

### Resource Management in Production

**Essential patterns for production deployments:**

**File: production_patterns.py**

\`\`\`python
     1â†’import logging
     2â†’from puffinflow import Agent, state, Priority
     3â†’from puffinflow.core.resources import (
     4â†’    ProductionResourceManager, ResourceHealthChecker,
     5â†’    ResourceAlertManager, ResourceOptimizer
     6â†’)
     7â†’
     8â†’# Configure production resource management
     9â†’resource_manager = ProductionResourceManager(
    10â†’    cpu_overcommit_ratio=1.2,      # 20% CPU overcommit
    11â†’    memory_overcommit_ratio=1.0,   # No memory overcommit
    12â†’    resource_reservation_buffer=0.1, # 10% buffer for emergencies
    13â†’    enable_resource_prediction=True,  # Predict future needs
    14â†’    enable_auto_scaling=True,        # Auto-scale resources
    15â†’    enable_cost_optimization=True    # Optimize for cost
    16â†’)
    17â†’
    18â†’# Health checking for resource systems
    19â†’health_checker = ResourceHealthChecker(
    20â†’    check_interval_seconds=30.0,     # Check every 30 seconds
    21â†’    cpu_health_threshold=0.9,        # Alert if CPU > 90%
    22â†’    memory_health_threshold=0.85,    # Alert if memory > 85%
    23â†’    disk_health_threshold=0.8,       # Alert if disk > 80%
    24â†’    network_health_threshold=0.7     # Alert if network > 70%
    25â†’)
    26â†’
    27â†’# Alert management for resource issues
    28â†’alert_manager = ResourceAlertManager(
    29â†’    email_alerts=True,
    30â†’    slack_webhook_url="https://hooks.slack.com/services/...",
    31â†’    pagerduty_integration_key="your_pagerduty_key",
    32â†’    alert_escalation_timeout=300.0   # Escalate after 5 minutes
    33â†’)
    34â†’
    35â†’# Resource optimizer for cost and performance
    36â†’optimizer = ResourceOptimizer(
    37â†’    optimization_goal="balanced",    # balanced, performance, cost
    38â†’    optimization_interval=3600.0,    # Optimize every hour
    39â†’    min_optimization_improvement=0.05 # Must improve by 5%
    40â†’)
    41â†’
    42â†’# Production agent with full resource management
    43â†’production_agent = Agent(
    44â†’    "production-workflow",
    45â†’    resource_manager=resource_manager
    46â†’)
    47â†’
    48â†’@state(cpu=2.0, memory=1024, timeout=300.0, priority=Priority.HIGH)
    49â†’async def production_critical_task(context):
    50â†’    print("ðŸ­ Production critical task starting...")
    51â†’    
    52â†’    try:
    53â†’        # Get resource health status
    54â†’        health_status = health_checker.get_current_health()
    55â†’        
    56â†’        if not health_status.is_healthy:
    57â†’            print("âš ï¸ System health issues detected:")
    58â†’            for issue in health_status.issues:
    59â†’                print(f"   {issue.severity}: {issue.message}")
    60â†’                
    61â†’                # Send alert for critical issues
    62â†’                if issue.severity == "critical":
    63â†’                    await alert_manager.send_alert(
    64â†’                        title="Critical Resource Issue",
    65â†’                        message=issue.message,
    66â†’                        severity="critical"
    67â†’                    )
    68â†’        
    69â†’        # Get resource optimization recommendations
    70â†’        optimization_recs = optimizer.get_recommendations()
    71â†’        if optimization_recs:
    72â†’            print("ðŸ’¡ Resource optimization recommendations:")
    73â†’            for rec in optimization_recs:
    74â†’                print(f"   {rec.type}: {rec.description} (savings: {rec.estimated_savings})")
    75â†’        
    76â†’        # Simulate critical production work
    77â†’        await asyncio.sleep(10)
    78â†’        
    79â†’        # Log resource usage for analysis
    80â†’        resource_usage = resource_manager.get_current_usage()
    81â†’        logging.info(f"Production task resource usage: CPU {resource_usage.cpu_utilization:.1f}%, Memory {resource_usage.memory_utilization:.1f}%")
    82â†’        
    83â†’        print("âœ… Production critical task complete")
    84â†’        
    85â†’    except Exception as e:
    86â†’        # Handle production errors with resource context
    87â†’        resource_context = resource_manager.get_resource_context()
    88â†’        error_message = f"Production task failed: {str(e)}"
    89â†’        error_details = f"Resource context: {resource_context}"
    90â†’        
    91â†’        logging.error(f"{error_message}\\n{error_details}")
    92â†’        
    93â†’        # Send critical alert
    94â†’        await alert_manager.send_alert(
    95â†’            title="Production Task Failure",
    96â†’            message=f"{error_message}\\n{error_details}",
    97â†’            severity="critical"
    98â†’        )
    99â†’        
   100â†’        raise
   101â†’
   102â†’# Resource monitoring callbacks for production
   103â†’@resource_manager.on_resource_pressure
   104â†’async def handle_resource_pressure(pressure_info):
   105â†’    print(f"ðŸ”¥ Resource pressure detected: {pressure_info.resource_type} at {pressure_info.utilization:.1f}%")
   106â†’    
   107â†’    # Implement load shedding or scaling
   108â†’    if pressure_info.utilization > 0.95:
   109â†’        print("ðŸš¨ Implementing emergency load shedding")
   110â†’        # Could pause non-critical tasks, scale up resources, etc.
   111â†’
   112â†’@optimizer.on_optimization_completed
   113â†’async def handle_optimization_complete(optimization_result):
   114â†’    print(f"âš¡ Resource optimization complete:")
   115â†’    print(f"   Performance improvement: {optimization_result.performance_improvement:.1f}%")
   116â†’    print(f"   Cost reduction: $\{optimization_result.cost_savings:.2f}/hour")
   117â†’    print(f"   Resource efficiency: {optimization_result.efficiency_improvement:.1f}%")
\`\`\`

---

## Quick Reference

### Resource Allocation Syntax

\`\`\`python
# Basic resource allocation
@state(cpu=2.0, memory=1024, timeout=60.0)
async def my_task(context): pass

# Using predefined profiles
@cpu_intensive        # 4.0 CPU, 1024MB memory
@memory_intensive      # 2.0 CPU, 4096MB memory
@gpu_accelerated       # 2.0 CPU, 2048MB memory, 1.0 GPU

# Priority-based allocation
@state(cpu=1.0, memory=512, priority=Priority.HIGH)
async def important_task(context): pass

# Custom resource requirements
@state(cpu=3.5, memory=2048, gpu=0.5, io_weight=2.0, network_weight=1.5)
async def complex_task(context): pass
\`\`\`

### Resource Pool Creation

\`\`\`python
from puffinflow.core.resources import ResourcePool, PriorityAllocator

# Create resource pool
pool = ResourcePool(
    total_cpu=16.0,
    total_memory=32768,
    total_gpu=4.0,
    allocator=PriorityAllocator()
)

# Agent with resource pool
agent = Agent("my-agent", resource_pool=pool)
\`\`\`

### Resource Monitoring

\`\`\`python
from puffinflow.core.resources import ResourceMonitor

monitor = ResourceMonitor(resource_pool)

# Get current usage
usage = monitor.get_current_usage()
print(f"CPU: {usage.cpu_utilization:.1f}%")
print(f"Memory: {usage.memory_utilization:.1f}%")

# Check for resource constraints
if monitor.is_resource_constrained():
    recommendations = monitor.get_optimization_recommendations()
\`\`\`

Resource management in Puffinflow ensures your workflows run efficiently, scale properly, and maintain high performance under varying load conditions. Start with basic resource allocation and gradually adopt advanced patterns as your needs grow.
`.trim();